ğŸ“„ Conversational RAG Q&A with PDF Upload & Chat History

This is a Conversational RAG (Retrieval-Augmented Generation) app built with Streamlit, allowing users to upload PDF documents and interact with their contents via natural language queries. It maintains chat history across sessions, reformulates context-aware questions, and provides concise, accurate answers using Groq's Gemma2-9b-It model.

ğŸš€ Features

âœ… Upload one or multiple PDFs.

âœ… Ask questions about the content.

âœ… Maintains per-session chat history.

âœ… Context-aware question reformulation.

âœ… Powered by HuggingFace embeddings + Groq LLMs.

âœ… Built with LangChain + Streamlit.

ğŸ§  Tech Stack
Component	Description
ğŸ§  LLM	Groq API (Gemma2-9b-It)
ğŸ” Embeddings	HuggingFace all-MiniLM-L6-v2
ğŸ§± Vector DB	ChromaDB (in-memory)
ğŸ“„ PDF Loader	PyPDFLoader from langchain_community
ğŸ’¬ Chat History	ChatMessageHistory per session
ğŸ–¥ï¸ Frontend	Streamlit
```
Langchain-project/
â””â”€â”€RagQnA/
    â”œâ”€â”€ Chat_pdf_app.py     # Main Streamlit app
    â”œâ”€â”€ .env                # HuggingFace token stored here
    â””â”€â”€ temp.pdf            # Temporary PDF used during processing
```
âš™ï¸ Setup Instructions
1. Clone the Repo
bash
```
git clone https://github.com/yourname/pdf-chat-rag-app.git
cd Langchain-project/4-RagQnA
```
2. Create a Virtual Environment
bash
```

python -m venv venv
venv\Scripts\activate   # On Window
```
3. Install Dependencies
bash
```

pip install -r requirements.txt
```
ğŸ Run the App
bash
```
streamlit run Chat_pdf_app.py
```
ğŸ–¼ï¸ UI Preview

<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/4d7454d6-eecb-4c74-9248-efe3670b69b8" />
<img width="1920" height="1080" alt="image" src="https://github.com/user-attachments/assets/7877661a-38ac-414f-9401-f46374b9db39" />

